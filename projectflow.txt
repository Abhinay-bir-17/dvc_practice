1. Create git repo and clone it in local. # $ 'first commit'
2. Create main.py and add code to it. (it will save a csv file to a new "data" folder)
3. Do a git add-commit-push before initializing dvc.
  # $ 'first commit before dvc'
# pip install dvc
4. Now we do "dvc init" (creates .dvcignore, .dvc)
5. Now do "mkdir S3" (creates a new S3 directory) # this is destination
   # in place os s3 we will put s3 link later
6. Now we do "dvc remote add -d myremote S3"
7. Next "dvc add data/"  # dvc is responsible for tracking anythin in data/
   Now it will ask to do: ("git rm -r --cached 'data'" and "git commit -m "stop tracking data"")
   Because initially we were tracking data/ folder from git so now we remove it for DVC to handle.
   # $ 'stop tracking data'
8. Again we do "dvc add data/" (creates data.dvc) then "git add .gitignore data.dvc"
   # data.dvc contains 'id' which will be used to fetch 'data' 
   # use ' dvc status' now, u see data nd pipelines r up to date
   # $ 'dvc initiated with data version 1'
9. Now - "dvc commit" and then "dvc push"
   # before this step, dvc was tracking 'data' but not added in s3,
   # after this step it adds in s3 folder

9. Do a git add-commit-push to mark this stage as first version of data.
    # $ '1st version of data saved' 

10. Now make changes to main.py to append a new row in data, 
    check changes via "dvc status"
    

11. Again - - "dvc commit" and then "dvc push"
     # to add to ur s3 bucket all files of 'data' folder , 
     # here s3 bucket is s3 folder
12. Then git add-commit-push (we're saving V2 of our data at this point)
     # $ '2nd version of data saved'
13. Check dvc/git status, everything should be upto date.
14. Now repeat step 10-12 for v3 of data.